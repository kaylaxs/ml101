sklearn 特征处理API
sklearn.processing
归一化
特点：通过对原始数据进行变换把数据映射到默认为[0,1]的区间
公式：X'=(x-min)/(max-min)
X''=X'*(mx-mi)+mi

注意：作用于每一列，max为一列的最大值，min为一列的最小值，那么X''为最终结果。mx，mi分别为制定区间默认mx为1，mi默认为0

计算公式：
特征1  特征2
90      2
60      4
75      3

特征1 第一组
x'=90-60 / 90-60=1
x‘’=x'*（1-0）+0=1

特征1 第二组
x'=60-60 / 60-60 =0
x''=x'*(1-0)=0


sklearn归一化API
sklearn.prepoccesing.MinMaxScaler (缩放的意思)
MinMaxScaler语法
MinMaxScaler(feature_range(0,1...)) (指定缩小到那个范围之内)
每个特征缩放到给定范围（默认[0，1]）
MinMaxScaler.fit_transform(x)
x:numpy array 格式的数据(n_samples,n_features)
返回值：转换后的形状相同的array


归一化步骤
1.实例化MinMaxScalar
2.通过fit_transform转换

特征的预处理：对数据进行处理，缺失值
三个特征同等重要的时候：进行归一化
里程数  公开数  消耗时间比   评价
x1      y1      z1        a
x2      y2      z2        b
x3      y3      z3        a
x4      y4      z4        c

(x1-x2)^2+(y1-y2)^2+(z1-z2)^2

目的：某一个特征对最终结果不会造成更大影响








标准化
1.特点：通过对原始数据进行变换把数据变化为均值为0，方差为1范围内
2. 公式：x'=x-mean / sigama
注意：作用于每一列，mean为平均值，sigma为标准差
var成为方差，var=(x1-mean)^2+(x2-mean)^2+.../n n为每个特征的样本数 ，sigma=var^1/2


对于归一化来说，如果出现异常点，影响了最大值和最小值，那么结果显然会发生改变
对于标准化来说，如果出现异常点，由于具有一定数据量，少量的异常点对于平均值影响并不大，从而方差改变较小


sklearn特征化API
scikit-learn.preprocessing.standardScaler
StandardScaler(...)
处理之后每一列所有数据都聚集在均值为0附近 方差为1
standardScaler.fit_transform(x)
x:numpy array格式的数据[n_samples,n_features]
返回值：转换后形状相同的array
standardScaler.mean_
原始数据中每列特征的平均值
standardScaler.std_
原始数据每列特征的方差


def mm():
  归一化处理
  mm=MinMaxScaler(feature_range=(2,3))
  data=mm.fit_transform([[...],[...],[...]]) 二维矩阵
  print(data)
  return None

def stand():
  标准化缩放
  std=standardScaler()
  std.fit_transform([[...],[...],[...]])
  print(data)
  return None

标准化总结
在已有样本足够多的情况下比较稳定，适合现代嘈杂的大数据场景


def im():
  缺失值处理
  im=Imputer(missing_values='Nan',strategy='mean',axis=0)
  data = im.fit_transform([[...],[...],[...]])
  print(data)
  return None

关于np.nan(np.Nan)
1. numpy 的数组中可以使用np.nan来代替缺失值，属于float类型
2.如果是文件中的一些缺失值，可以替换成nan，通过np.array转换成float型的数组即可
